#  https://kafka.apache.org/documentation/#operations

# Create a Kafka topic using command line
kafka-topics.sh --create --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
                --topic streaming.week2.tweets \
                --partitions 3 \
                --replication-factor 2

# list topics - should see three partitions for topic streaming.week2.tweets
kafka-topics.sh --zookeeper zookeeper:2181 --list

# if you ever would like to delete a topic to restart from scratch
kafka-topics.sh --delete --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094  --topic streaming.week2.tweets

# describe a topic to see # of partitions and replicas
kafka-topics.sh --zookeeper zookeeper:2181 --topic streaming.week2.tweets --describe

# run the KafkaSimpleTweetConsumer in the editor to produce tweets

# consume tweets and display in the console
kafka-console-consumer.sh --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
    --topic streaming.week2.tweets \
    --from-beginning \
    --formatter kafka.tools.DefaultMessageFormatter \
    --property print.key=true \
    --property print.value=true \
    --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \
    --property value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

# reset partition off set to the earliest for consumer group id "streamingcourse.week2.basic.KafkaSimpleTweetConsumer"
kafka-consumer-groups.sh --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
 --execute --reset-offsets \
 --group streamingcourse.week2.basic.KafkaSimpleTweetConsumer \
 --topic streaming.week2.tweets \
 --to-earliest

# can confirm using the kafka drop UI, the Consumer Offset column should contain 0 for each partition
http://localhost:9000/consumer/streamingcourse.week2.basic.KafkaSimpleTweetConsumer

# reset partition off set to the earliest for consumer group id "streamingcourse.week2.basic.KafkaConsumerGroupTweetConsumer"
kafka-consumer-groups.sh --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
  --execute --reset-offsets \
  --group streamingcourse.week2.basic.KafkaConsumerGroupTweetConsumer \
  --topic streaming.week2.tweets \
  --to-earliest


# can confirm using the kafka drop UI, the Consumer Offset column should contain 0 for each partition
http://localhost:9000/consumer/streamingcourse.week2.basic.KafkaConsumerGroupTweetConsumer


# ====================== JSON related  =================================
# Create a Kafka topic using command line
kafka-topics.sh --create --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
                 --topic streaming.week2.mobile \
                 --partitions 3 \
                 --replication-factor 2

kafka-topics.sh --delete --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094  --topic streaming.week2.mobile

# =============================================================================
# ===================== Kafka Streams related =================================
# =============================================================================

# create a topic to read message to perform word count
# you can do this from Kafkadrop UI as well
kafka-topics.sh --create \
    --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
    --replication-factor 1 \
    --partitions 2 \
    --topic week2-wordcount-input


# create a topic to display to send word count output to
kafka-topics.sh --create \
    --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
    --replication-factor 1 \
    --partitions 1 \
    --topic week2-wordcount-output

# verify the input and output topic using Kafdrop UI or commands below
kafka-topics.sh --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
    --describe -topic week2-wordcount-input

kafka-topics.sh --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
    --describe -topic week2-wordcount-output

# consume the word count output
kafka-console-consumer.sh --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 \
    --topic week2-wordcount-output \
    --from-beginning \
    --property print.key=true


# run the KStreamWordCount application


# produce messages to week2-wordcount-input for
kafka-console-producer.sh --broker-list kafka1:29092,kafka2:29093,kafka3:29094 \
     --topic week2-wordcount-input


# =============================================================================
# when things are messed up and you want to reset everything
# =============================================================================

# reset the internal state
# https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams+Application+Reset+Tool
kafka-streams-application-reset.sh --application-id kstreams-wordcount-app --bootstrap-servers kafka1:29092,kafka2:29093,kafka3:29094 --input-topics wordcount-input


# when encountered an error "Tried to lookup lag for unknown task 1_0"
# run this command on the machine that runs the Kafka Streams application
# remove /private/tmp/kafka-streams/kstreams-wordcount-app directory
* rm -r /private/tmp/kafka-streams/kstreams-wordcount-app